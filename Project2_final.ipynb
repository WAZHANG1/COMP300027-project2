{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>steps</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>duration_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wi gal s chicken rice stove top dish made heal...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>['in saucepan , melt margarine and combine wit...</td>\n",
       "      <td>['margarine', 'olive oil', 'celery', 'onion', ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irish pin oats</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>['melt 1 tbs butter in a small saucepan over m...</td>\n",
       "      <td>['butter', 'pinhead oats', 'water', 'half-and-...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cheesy beef   n biscuit casserole</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>['brown ground beef , onion and green pepper',...</td>\n",
       "      <td>['ground beef', 'onion', 'green pepper', 'toma...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemonade chicken  oamc</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>['brown chicken in oil', 'combine all ingredie...</td>\n",
       "      <td>['boneless skinless chicken', 'frozen lemonade...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>graham and peanut butter bon bons</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>['set almond bark aside', 'mix remaining ingre...</td>\n",
       "      <td>['graham cracker crumbs', 'crunchy peanut butt...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  n_steps  n_ingredients  \\\n",
       "0  wi gal s chicken rice stove top dish made heal...        6             12   \n",
       "1                                     irish pin oats        9              5   \n",
       "2                  cheesy beef   n biscuit casserole       15             10   \n",
       "3                             lemonade chicken  oamc       10              8   \n",
       "4                  graham and peanut butter bon bons        6              5   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['in saucepan , melt margarine and combine wit...   \n",
       "1  ['melt 1 tbs butter in a small saucepan over m...   \n",
       "2  ['brown ground beef , onion and green pepper',...   \n",
       "3  ['brown chicken in oil', 'combine all ingredie...   \n",
       "4  ['set almond bark aside', 'mix remaining ingre...   \n",
       "\n",
       "                                         ingredients  duration_label  \n",
       "0  ['margarine', 'olive oil', 'celery', 'onion', ...             2.0  \n",
       "1  ['butter', 'pinhead oats', 'water', 'half-and-...             2.0  \n",
       "2  ['ground beef', 'onion', 'green pepper', 'toma...             2.0  \n",
       "3  ['boneless skinless chicken', 'frozen lemonade...             2.0  \n",
       "4  ['graham cracker crumbs', 'crunchy peanut butt...             2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_csv('recipe_train.csv')\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['steps'] = train_raw['steps'].apply(eval)\n",
    "train_raw['ingredients'] = train_raw['ingredients'].apply(eval)\n",
    "train_raw['steps'] = train_raw['steps'].apply(' '.join)\n",
    "train_raw['ingredients'] = train_raw['ingredients'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(train_raw.drop(columns='duration_label'), train_raw['duration_label'], test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes---Count Vectoriser (name+steps+ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = x_train['name'] + \" \" + x_train['steps'] + \" \" + x_train['ingredients'] \n",
    "dev_text = x_dev['name'] + \" \" + x_dev['steps'] + \" \" + x_dev['ingredients'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "cv = CountVectorizer(stop_words='english').fit(train_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_steps_cv = cv.transform(train_text)\n",
    "x_dev_steps_cv = cv.transform(dev_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7538, 0.7213)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train_steps_cv, y_train)\n",
    "mnb.score(x_train_steps_cv, y_train), mnb.score(x_dev_steps_cv, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71533333, 0.72433333, 0.72683333, 0.7285    , 0.723     ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use cross validation to check overfitting\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(mnb, x_train_steps_cv, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the text of steps, ingredients and name combine together, we get a accuracy of 0.7213 for the development set. \n",
    "Try only use the text of steps(it have the most words hence we might get the most information form this feature), there is a slight imporvement. \n",
    "Then try add in the name feature, the accuracy have a further improvement compare to when we only use the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes---Count Vectoriser (steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7598666666666667, 0.7234)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text1 = x_train['steps'] \n",
    "dev_text1 = x_dev['steps'] \n",
    "cv1 = CountVectorizer(stop_words='english').fit(train_text1)\n",
    "x_train_steps_cv1 = cv.transform(train_text1)\n",
    "x_dev_steps_cv1 = cv.transform(dev_text1)\n",
    "mnb1 = MultinomialNB()\n",
    "mnb1.fit(x_train_steps_cv1, y_train)\n",
    "mnb1.score(x_train_steps_cv1, y_train), mnb.score(x_dev_steps_cv1, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes---Count Vectoriser (name+steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7692666666666667, 0.7247)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text2 = x_train['name'] + \" \" + x_train['steps'] \n",
    "dev_text2 = x_dev['name'] + \" \" + x_dev['steps'] \n",
    "cv2 = CountVectorizer(stop_words='english').fit(train_text2)\n",
    "x_train_steps_cv2 = cv.transform(train_text2)\n",
    "x_dev_steps_cv2 = cv.transform(dev_text2)\n",
    "mnb2 = MultinomialNB()\n",
    "mnb2.fit(x_train_steps_cv2, y_train)\n",
    "mnb2.score(x_train_steps_cv2, y_train), mnb.score(x_dev_steps_cv2, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = pd.read_csv('recipe_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw['steps'] = test_raw['steps'].apply(eval)\n",
    "test_raw['ingredients'] = test_raw['ingredients'].apply(eval)\n",
    "test_raw['steps'] = test_raw['steps'].apply(' '.join)\n",
    "test_raw['ingredients'] = test_raw['ingredients'].apply(' '.join)\n",
    "test_text = test_raw['name'] + \" \" + test_raw['steps'] + \" \" + test_raw['ingredients'] \n",
    "x_test_text_cv = cv.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2., ..., 1., 1., 2.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = mnb.predict(x_test_text_cv)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>duration_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  duration_label\n",
       "0         1             2.0\n",
       "1         2             1.0\n",
       "2         3             2.0\n",
       "3         4             1.0\n",
       "4         5             2.0\n",
       "...     ...             ...\n",
       "9995   9996             2.0\n",
       "9996   9997             2.0\n",
       "9997   9998             1.0\n",
       "9998   9999             1.0\n",
       "9999  10000             2.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'id': list(range(1,10001)), 'duration_label': list(prediction)}, columns=['id', 'duration_label'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes---tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english').fit(x_train['steps'])\n",
    "# train_text2 = name+steps\n",
    "x_train_steps_tfidf = tfidf.transform(train_text2)\n",
    "x_dev_steps_tfidf = tfidf.transform(dev_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.733, 0.6994)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb3 = MultinomialNB()\n",
    "mnb3.fit(x_train_steps_tfidf, y_train)\n",
    "mnb3.score(x_train_steps_tfidf, y_train), mnb3.score(x_dev_steps_tfidf, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we can see that by using tfidf to get the weight of each word does not produce a better performance for multinomial NB which is resonable since "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)  \n",
    "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
    "TP = np.diag(confusion_matrix)\n",
    "TN = confusion_matrix.values.sum() - (FP + FN + TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3004 1386   87]\n",
      " [ 978 3964   84]\n",
      " [  87   99  311]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mnb_pred = mnb2.predict(x_dev_steps_cv1)\n",
    "print(confusion_matrix(y_dev, mnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-d3de1d1d1fb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Recall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmnb_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \"\"\"\n\u001b[1;32m-> 1735\u001b[1;33m     _, r, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1736\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1434\u001b[0m                                     pos_label)\n\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1263\u001b[1;33m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[0;32m   1264\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_dev, mnb_pred)\n",
    "\n",
    "# Recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_dev, mnb_pred)\n",
    "\n",
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_dev, mnb_pred)\n",
    "\n",
    "accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC---CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chloe\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8772, 0.7828)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC().fit(x_train_steps_cv, y_train)\n",
    "svc.score(x_train_steps_cv, y_train), svc.score(x_dev_steps_cv, y_dev)\n",
    "svc = LinearSVC().fit(x_train_steps_tfidf, y_train)\n",
    "svc.score(x_train_steps_tfidf, y_train), svc.score(x_dev_steps_tfidf, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC---tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8772, 0.7828)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC().fit(x_train_steps_tfidf, y_train)\n",
    "svc.score(x_train_steps_tfidf, y_train), svc.score(x_dev_steps_tfidf, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression---CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.924, 0.7725)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000).fit(x_train_steps_cv, y_train)\n",
    "lr.score(x_train_steps_cv, y_train), lr.score(x_dev_steps_cv, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression---tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8356333333333333, 0.7876)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000).fit(x_train_steps_tfidf, y_train)\n",
    "lr.score(x_train_steps_tfidf, y_train), lr.score(x_dev_steps_tfidf, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mutual info on cv\n",
    "kbest = SelectKBest(score_func=mutual_info_classif, k=4000).fit(x_train_steps_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use f_classif on tfidf\n",
    "kbest = SelectKBest(score_func=f_classif, k=4000).fit(x_train_steps_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use chi2 on tfidf\n",
    "kbest = SelectKBest(score_func=chi2, k=4000).fit(x_train_steps_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8016666666666666, 0.7821)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGDClassifier\n",
    "sgd = SGDClassifier(loss='log', max_iter=1000).fit(x_train_steps_tfidf, y_train)\n",
    "sgd.score(x_train_steps_tfidf, y_train), sgd.score(x_dev_steps_tfidf, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('kbest', SelectKBest()), ('clf', SGDClassifier(random_state=2))\n",
    "    ]\n",
    ")\n",
    "parameters = {\n",
    "    'kbest__score_func': (f_classif, chi2),\n",
    "    'kbest__k': (1000, 4000, 10000, 'all'),\n",
    "    'clf__loss': ('hinge', 'log'),\n",
    "    'clf__alpha': (1e-5, 1e-4, 1e-3, 1e-2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def grid_search(pipeline, parameters, X, y):\n",
    "    gs = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    print('Performing grid search...')\n",
    "    print('pipeline:', [name for name, _ in pipeline.steps])\n",
    "    print('parameters:')\n",
    "    print(parameters)\n",
    "    t0 = time()\n",
    "    gs.fit(X, y)\n",
    "    print(\"done in %0.3fs\" % (time()-t0))\n",
    "    print()\n",
    "    \n",
    "    mean_score = gs.cv_results_['mean_test_score']\n",
    "    param_set = gs.cv_results_['params']\n",
    "    for idx in mean_score.argsort()[-5:]:\n",
    "        print(param_set[idx])\n",
    "        print(gs.cv_results_['mean_test_score'][idx])\n",
    "        print('='*30)\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['kbest', 'clf']\n",
      "parameters:\n",
      "{'kbest__score_func': (<function f_classif at 0x000001CFF1AF2310>, <function chi2 at 0x000001CFF1AF2670>), 'kbest__k': (1000, 4000, 10000, 'all'), 'clf__loss': ('hinge', 'log'), 'clf__alpha': (1e-05, 0.0001, 0.001, 0.01)}\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 320 out of 320 | elapsed:   22.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 22.858s\n",
      "\n",
      "{'clf__alpha': 0.0001, 'clf__loss': 'hinge', 'kbest__k': 10000, 'kbest__score_func': <function f_classif at 0x000001CFF1AF2310>}\n",
      "0.7863\n",
      "==============================\n",
      "{'clf__alpha': 0.0001, 'clf__loss': 'hinge', 'kbest__k': 4000, 'kbest__score_func': <function chi2 at 0x000001CFF1AF2670>}\n",
      "0.7871333333333334\n",
      "==============================\n",
      "{'clf__alpha': 0.0001, 'clf__loss': 'hinge', 'kbest__k': 10000, 'kbest__score_func': <function chi2 at 0x000001CFF1AF2670>}\n",
      "0.7874\n",
      "==============================\n",
      "{'clf__alpha': 0.0001, 'clf__loss': 'hinge', 'kbest__k': 'all', 'kbest__score_func': <function f_classif at 0x000001CFF1AF2310>}\n",
      "0.7881\n",
      "==============================\n",
      "{'clf__alpha': 0.0001, 'clf__loss': 'hinge', 'kbest__k': 'all', 'kbest__score_func': <function chi2 at 0x000001CFF1AF2670>}\n",
      "0.7881\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "result = grid_search(pipeline, parameters, x_train_steps_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result of the SDG classifier, we can see that the models with the top performance all have a alpha of 0.0001 and hinge loss. The score function does not make a much difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembel Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.max voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7882"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from statistics import mode\n",
    "\n",
    "pred1=svc.predict(x_dev_steps_tfidf)\n",
    "pred2=lr.predict(x_dev_steps_tfidf)\n",
    "pred3=sgd.predict(x_dev_steps_tfidf)\n",
    "\n",
    "final_pred = np.array([])\n",
    "for i in range(0,len(x_dev)):\n",
    "    final_pred = np.append(final_pred, mode([pred1[i], pred2[i], pred3[i]]))\n",
    "    \n",
    "accuracy_train = accuracy_score(y_dev,final_pred)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on the test set use max voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = test_raw['name'] + \" \" + test_raw['steps']\n",
    "x_test_steps_tfidf = tfidf.transform(test_text)\n",
    "\n",
    "pred1_test=svc.predict(x_test_steps_tfidf)\n",
    "pred2_test=lr.predict(x_test_steps_tfidf)\n",
    "pred3_test=sgd.predict(x_test_steps_tfidf)\n",
    "\n",
    "prediction2 = np.array([])\n",
    "for i in range(0,len(test_text)):\n",
    "    prediction2 = np.append(prediction2, mode([pred1_test[i], pred2_test[i], pred3_test[i]]))\n",
    "    \n",
    "results2 = pd.DataFrame({'id': list(range(1,10001)), 'duration_label': list(prediction2)}, columns=['id', 'duration_label'])\n",
    "results2.to_csv(\"results2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.73,\n",
       " 0.734,\n",
       " 0.7347,\n",
       " 0.7338,\n",
       " 0.7391,\n",
       " 0.7424,\n",
       " 0.7408,\n",
       " 0.7444,\n",
       " 0.7505,\n",
       " 0.7485,\n",
       " 0.7546]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy_train_list = []\n",
    "for i in range(10,21):\n",
    "    rf = RandomForestClassifier(max_depth=i)\n",
    "\n",
    "    # fit the model with the training data\n",
    "    rf.fit(x_train_steps_tfidf, y_train)\n",
    "\n",
    "    # predict the target on the train dataset\n",
    "    predict_train = rf.predict(x_dev_steps_tfidf)\n",
    "\n",
    "    # Accuray Score on train dataset\n",
    "    accuracy_train = accuracy_score(y_dev,predict_train)\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "accuracy_train_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result we can see that the accuracy increase as the max depth of the tree increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7778"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, max_depth=40)\n",
    "\n",
    "# fit the model with the training data\n",
    "rf.fit(x_train_steps_tfidf, y_train)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = rf.predict(x_dev_steps_tfidf)\n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(y_dev,predict_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth=40, n_estimators=100: 0.77\n",
    "max_depth=40, n_estimators=200: 0.7776\n",
    "max_depth=100, n_estimators=100: 0.778"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "varie the max depth or the number of trees can improve the accuracy but does not lead to a large change where it increases the complexity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN (not complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = pd.DataFrame({'n_steps': x_train['n_steps'] , 'n_ingredients': x_train['n_ingredients']}, columns=['n_steps', 'n_ingredients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6015"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train1, y_train)\n",
    "classifier.score(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = pd.DataFrame({'n_steps': x_train['n_steps'] , 'n_ingredients': x_train['n_ingredients']}, columns=['n_steps', 'n_ingredients'])\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train1, y_train)\n",
    "classifier.score(X_train1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree (not complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iris' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-dff07c6d8f19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdecision_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdecision_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_steps_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'iris' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "decision_tree = decision_tree.fit(x_train_steps_cv, y_train)\n",
    "r = export_text(decision_tree, feature_names=iris['feature_names'])\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x20724 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1571310 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_steps_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['name', 'n_steps', 'n_ingredients', 'steps', 'ingredients'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
